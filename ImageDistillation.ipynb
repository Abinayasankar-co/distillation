{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device : {device}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data',train=True,download=True,transform=transforms_cifar)\n",
    "test_dataset = datasets.CIFAR10(root='./data',train=False,download=True,transform=transforms_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine Custom Normalization Metrics\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "N_CHANNELS = 1\n",
    "\n",
    "dataset = datasets.MNIST(\"data\", download=True,\n",
    "                 train=True, transform=transforms.ToTensor())\n",
    "full_loader = torch.utils.data.DataLoader(dataset, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "before = time()\n",
    "mean = torch.zeros(1)\n",
    "std = torch.zeros(1)\n",
    "print('==> Computing mean and std..')\n",
    "for inputs, _labels in tqdm(full_loader):\n",
    "    for i in range(N_CHANNELS):\n",
    "        mean[i] += inputs[:,i,:,:].mean()\n",
    "        std[i] += inputs[:,i,:,:].std()\n",
    "mean.div_(len(dataset))\n",
    "std.div_(len(dataset))\n",
    "print(mean, std)\n",
    "\n",
    "print(\"time elapsed: \", time()-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loaders = torch.utils.data.DataLoader(train_dataset,batch_size=128,shuffle=True,num_workers=2)\n",
    "test_loaders = torch.utils.data.DataLoader(test_dataset,batch_size=128,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(DeepNN,self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,32,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.features(X)  \n",
    "        X = torch.flatten(X,1)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightNN(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "      super(LightNN,self).__init__()\n",
    "      self.features = nn.Sequential(\n",
    "         nn.Conv2d(3,16,kernel_size=3,padding=1),\n",
    "         nn.ReLU(),\n",
    "         nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "         nn.Conv2d(16,16,kernel_size=3,padding=1),\n",
    "         nn.ReLU(),\n",
    "         nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "      )\n",
    "\n",
    "      self.classifier = nn.Sequential(\n",
    "        nn.Linear(1024,256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256,num_classes)\n",
    "\n",
    "      )\n",
    "\n",
    "    def forward(self,X):\n",
    "       X = self.features(X)\n",
    "       X = torch.flatten(X,1)\n",
    "       X = self.classifier(X)\n",
    "       return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, learning_rate, device):\n",
    "    criterion  = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    " \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        runing_loss = 0.0\n",
    "        for input, label in train_loader:\n",
    "            input , label = input.to(device), label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = criterion(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runing_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch +1}/ {epochs} , Loss: {runing_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "def test(model,test_loader,device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 50 , Loss: 1.804095080136643\n",
      "Epoch 2/ 50 , Loss: 1.4708543390874058\n",
      "Epoch 3/ 50 , Loss: 1.3569431280540993\n",
      "Epoch 4/ 50 , Loss: 1.271607019102482\n",
      "Epoch 5/ 50 , Loss: 1.2065557808522374\n",
      "Epoch 6/ 50 , Loss: 1.1477777526506683\n",
      "Epoch 7/ 50 , Loss: 1.0926402209664854\n",
      "Epoch 8/ 50 , Loss: 1.041032755618815\n",
      "Epoch 9/ 50 , Loss: 0.9953873357199647\n",
      "Epoch 10/ 50 , Loss: 0.9544498040852949\n",
      "Epoch 11/ 50 , Loss: 0.9153146877922975\n",
      "Epoch 12/ 50 , Loss: 0.8775202926162564\n",
      "Epoch 13/ 50 , Loss: 0.8434965726359726\n",
      "Epoch 14/ 50 , Loss: 0.8122409428172099\n",
      "Epoch 15/ 50 , Loss: 0.7816535925011501\n",
      "Epoch 16/ 50 , Loss: 0.7487331043423899\n",
      "Epoch 17/ 50 , Loss: 0.7224821343141443\n",
      "Epoch 18/ 50 , Loss: 0.6871171735436715\n",
      "Epoch 19/ 50 , Loss: 0.663576886781951\n",
      "Epoch 20/ 50 , Loss: 0.6347559724012604\n",
      "Epoch 21/ 50 , Loss: 0.6047375401877382\n",
      "Epoch 22/ 50 , Loss: 0.5815140062280933\n",
      "Epoch 23/ 50 , Loss: 0.5551274838045125\n",
      "Epoch 24/ 50 , Loss: 0.5317892457365685\n",
      "Epoch 25/ 50 , Loss: 0.5087172233540079\n",
      "Epoch 26/ 50 , Loss: 0.4822124786998915\n",
      "Epoch 27/ 50 , Loss: 0.45906132048048326\n",
      "Epoch 28/ 50 , Loss: 0.43562216763301276\n",
      "Epoch 29/ 50 , Loss: 0.41501895896614055\n",
      "Epoch 30/ 50 , Loss: 0.3909765515104889\n",
      "Epoch 31/ 50 , Loss: 0.3648803822143608\n",
      "Epoch 32/ 50 , Loss: 0.34532739934713946\n",
      "Epoch 33/ 50 , Loss: 0.32605651505005634\n",
      "Epoch 34/ 50 , Loss: 0.29912122070332015\n",
      "Epoch 35/ 50 , Loss: 0.2854767833143244\n",
      "Epoch 36/ 50 , Loss: 0.27097025517460027\n",
      "Epoch 37/ 50 , Loss: 0.25312914129565744\n",
      "Epoch 38/ 50 , Loss: 0.23311537246951056\n",
      "Epoch 39/ 50 , Loss: 0.21674792775336435\n",
      "Epoch 40/ 50 , Loss: 0.2066974697820366\n",
      "Epoch 41/ 50 , Loss: 0.19523798506659315\n",
      "Epoch 42/ 50 , Loss: 0.17802899650981663\n",
      "Epoch 43/ 50 , Loss: 0.166697925980896\n",
      "Epoch 44/ 50 , Loss: 0.15869319694273917\n",
      "Epoch 45/ 50 , Loss: 0.14777629064095904\n",
      "Epoch 46/ 50 , Loss: 0.13765226622752827\n",
      "Epoch 47/ 50 , Loss: 0.12818347357804208\n",
      "Epoch 48/ 50 , Loss: 0.12000533078065918\n",
      "Epoch 49/ 50 , Loss: 0.11089263335251442\n",
      "Epoch 50/ 50 , Loss: 0.1073909014882639\n",
      "Test Accuracy: 71.77%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "nn_deep = DeepNN(num_classes=10).to(device)\n",
    "train(nn_deep,train_loaders,50,5e-5,device)\n",
    "test_accuracy_deep = test(nn_deep,test_loaders,device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "nn_light = LightNN(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(nn_deep.state_dict(), \"final_BLSTM_model.pth\")\n",
    "print(f\"Final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of 1st Layer of nn_light 2.327361822128296\n",
      "Norm of 1st Layer of new_nn_light: 2.327361822128296\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "new_nn_light = LightNN(num_classes=10).to(device) \n",
    "print('Norm of 1st Layer of nn_light', torch.norm(nn_light.features[0].weight).item())\n",
    "print(\"Norm of 1st Layer of new_nn_light:\", torch.norm(new_nn_light.features[0].weight).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNN parameters: 1,186,986\n",
      "LightNN parameters: 267,738\n"
     ]
    }
   ],
   "source": [
    "total_params_deep = \"{:,}\".format(sum(p.numel() for p in nn_deep.parameters()))\n",
    "print(f\"DeepNN parameters: {total_params_deep}\")\n",
    "total_params_light = \"{:,}\".format(sum(p.numel() for p in nn_light.parameters()))\n",
    "print(f\"LightNN parameters: {total_params_light}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 50 , Loss: 1.979577873064124\n",
      "Epoch 2/ 50 , Loss: 1.6811188066097171\n",
      "Epoch 3/ 50 , Loss: 1.561907938679161\n",
      "Epoch 4/ 50 , Loss: 1.4894302720608918\n",
      "Epoch 5/ 50 , Loss: 1.433642453854651\n",
      "Epoch 6/ 50 , Loss: 1.3907219924585288\n",
      "Epoch 7/ 50 , Loss: 1.352692410464177\n",
      "Epoch 8/ 50 , Loss: 1.3204457982421836\n",
      "Epoch 9/ 50 , Loss: 1.2930744776640402\n",
      "Epoch 10/ 50 , Loss: 1.2680785887686492\n",
      "Epoch 11/ 50 , Loss: 1.2470414239122434\n",
      "Epoch 12/ 50 , Loss: 1.2286432600387223\n",
      "Epoch 13/ 50 , Loss: 1.2091225993907666\n",
      "Epoch 14/ 50 , Loss: 1.1921184093446073\n",
      "Epoch 15/ 50 , Loss: 1.1772517804294595\n",
      "Epoch 16/ 50 , Loss: 1.161402896389632\n",
      "Epoch 17/ 50 , Loss: 1.1468045964570301\n",
      "Epoch 18/ 50 , Loss: 1.1341804839156169\n",
      "Epoch 19/ 50 , Loss: 1.1203850059558058\n",
      "Epoch 20/ 50 , Loss: 1.1097121276818882\n",
      "Epoch 21/ 50 , Loss: 1.0942824571333882\n",
      "Epoch 22/ 50 , Loss: 1.0808643308441963\n",
      "Epoch 23/ 50 , Loss: 1.071204699671177\n",
      "Epoch 24/ 50 , Loss: 1.057097227067289\n",
      "Epoch 25/ 50 , Loss: 1.0488391821951513\n",
      "Epoch 26/ 50 , Loss: 1.0373247616431291\n",
      "Epoch 27/ 50 , Loss: 1.024498630515145\n",
      "Epoch 28/ 50 , Loss: 1.0143740808262545\n",
      "Epoch 29/ 50 , Loss: 1.0031350046167593\n",
      "Epoch 30/ 50 , Loss: 0.9945429101624452\n",
      "Epoch 31/ 50 , Loss: 0.9846150635758324\n",
      "Epoch 32/ 50 , Loss: 0.9750741743065817\n",
      "Epoch 33/ 50 , Loss: 0.968989302282748\n",
      "Epoch 34/ 50 , Loss: 0.957457266500234\n",
      "Epoch 35/ 50 , Loss: 0.9498825044278294\n",
      "Epoch 36/ 50 , Loss: 0.9383301841633399\n",
      "Epoch 37/ 50 , Loss: 0.9323797137536052\n",
      "Epoch 38/ 50 , Loss: 0.9237711915884481\n",
      "Epoch 39/ 50 , Loss: 0.9167582176225569\n",
      "Epoch 40/ 50 , Loss: 0.9092898838355413\n",
      "Epoch 41/ 50 , Loss: 0.9007166788706085\n",
      "Epoch 42/ 50 , Loss: 0.891575904453502\n",
      "Epoch 43/ 50 , Loss: 0.883599690311705\n",
      "Epoch 44/ 50 , Loss: 0.8780125539626003\n",
      "Epoch 45/ 50 , Loss: 0.869350012763382\n",
      "Epoch 46/ 50 , Loss: 0.8629030169123579\n",
      "Epoch 47/ 50 , Loss: 0.8593891503865762\n",
      "Epoch 48/ 50 , Loss: 0.8498073515989591\n",
      "Epoch 49/ 50 , Loss: 0.8453249952677265\n",
      "Epoch 50/ 50 , Loss: 0.8346399852381948\n",
      "Test Accuracy: 66.32%\n"
     ]
    }
   ],
   "source": [
    "train(nn_light, train_loaders, epochs=50, learning_rate=5e-5, device=device)\n",
    "test_accuracy_light_ce = test(nn_light, test_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(nn_light.state_dict(), \"NNLight.pth\")\n",
    "print(\"Final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of 1st layer for deep_nn: 7.2851409912109375\n",
      "Norm of 1st layer for modified_deep_nn: 7.2851409912109375\n",
      "Norm of 1st layer: 2.327361822128296\n"
     ]
    }
   ],
   "source": [
    "class ModifiedDeepNN(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "        super(ModifiedDeepNN,self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,128,padding=1,kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,32,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.features(X)\n",
    "        flattened_conv_output = torch.flatten(X,1)\n",
    "        X = self.classifier(flattened_conv_output)\n",
    "        flattened_conv_output_after_pooling = torch.nn.functional.avg_pool1d(flattened_conv_output,2)\n",
    "        return X, flattened_conv_output_after_pooling\n",
    "\n",
    "\n",
    "class ModifiedLightNN(nn.Module):\n",
    "    def __init__(self,num_classes = 10):\n",
    "        super(ModifiedLightNN,self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,16,padding=1,kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(16,16,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256,num_classes)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.features(X)\n",
    "        flattened_conv_output = torch.flatten(X,1)\n",
    "        X = self.classifier(flattened_conv_output)\n",
    "        return X, flattened_conv_output\n",
    "\n",
    "\n",
    "modified_nn_deep = ModifiedDeepNN(num_classes=10).to(device)\n",
    "modified_nn_deep.load_state_dict(nn_deep.state_dict())\n",
    "\n",
    "print(\"Norm of 1st layer for deep_nn:\", torch.norm(nn_deep.features[0].weight).item())\n",
    "print(\"Norm of 1st layer for modified_deep_nn:\", torch.norm(modified_nn_deep.features[0].weight).item())\n",
    "\n",
    "torch.manual_seed(42)\n",
    "modified_nn_light = ModifiedLightNN(num_classes=10).to(device)\n",
    "print(\"Norm of 1st layer:\", torch.norm(modified_nn_light.features[0].weight).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student logits Shape: torch.Size([128, 10])\n",
      "Student Hidden Representation Shape: torch.Size([128, 1024])\n",
      "Teacher logits Shape: torch.Size([128, 10])\n",
      "Teacher Hidden Representation Shape: torch.Size([128, 1024])\n"
     ]
    }
   ],
   "source": [
    "#for Development Purpose - Giving a seed to check for Dimension \n",
    "sample_input = torch.randn(128,3,32,32).to(device)\n",
    "logits , hidden_representation = modified_nn_light(sample_input)\n",
    "print(\"Student logits Shape:\" , logits.shape) #batch_size x totalclass\n",
    "print(\"Student Hidden Representation Shape:\", hidden_representation.shape) # batchsize X hiddenrep\n",
    "logits , hidden_representation = modified_nn_deep(sample_input)\n",
    "print(\"Teacher logits Shape:\" , logits.shape) #batch_size x totalclass\n",
    "print(\"Teacher Hidden Representation Shape:\", hidden_representation.shape) # batchsize X hiddenrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxPolling Cosine Changes Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cosine_loss(\n",
    "        teacher,\n",
    "        student,\n",
    "        train_loaders,\n",
    "        epochs,\n",
    "        learning_rate,\n",
    "        hidden_rep_loss_weight,\n",
    "        ce_loss_weight,\n",
    "        device\n",
    "):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    optimizer = optim.Adam(student.parameters(),lr = learning_rate)\n",
    "\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs , labels in train_loaders:\n",
    "            inputs , labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                _, teacher_hidden_representation = teacher(inputs)\n",
    "            \n",
    "            studen_logits, student_hidden_representation = student(inputs)\n",
    "\n",
    "            hidden_rep_loss = cosine_loss(student_hidden_representation,teacher_hidden_representation,target = torch.ones(inputs.size(0)).to(device))\n",
    "\n",
    "            label_loss = ce_loss(studen_logits,labels)\n",
    "\n",
    "            loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight*label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loaders)}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_outputs(model, test_loaders, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loaders:\n",
    "            inputs , labels = inputs.to(device) , labels.to(device)\n",
    "\n",
    "            outputs , _ = model(inputs)\n",
    "            _ , predicted = torch.max(outputs.data,1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy : {accuracy:.2f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.209270174241127\n",
      "Epoch 2/50, Loss: 1.1756770205314813\n",
      "Epoch 3/50, Loss: 1.1529140053197855\n",
      "Epoch 4/50, Loss: 1.1325664690998205\n",
      "Epoch 5/50, Loss: 1.115619655155465\n",
      "Epoch 6/50, Loss: 1.1018539593957575\n",
      "Epoch 7/50, Loss: 1.0868908183653947\n",
      "Epoch 8/50, Loss: 1.0750122553552204\n",
      "Epoch 9/50, Loss: 1.0646017195318667\n",
      "Epoch 10/50, Loss: 1.0527007515778017\n",
      "Epoch 11/50, Loss: 1.0446436037797757\n",
      "Epoch 12/50, Loss: 1.0352031658677494\n",
      "Epoch 13/50, Loss: 1.024368842239575\n",
      "Epoch 14/50, Loss: 1.0166030632870278\n",
      "Epoch 15/50, Loss: 1.0072967038130212\n",
      "Epoch 16/50, Loss: 0.9997390784570933\n",
      "Epoch 17/50, Loss: 0.9931838405711572\n",
      "Epoch 18/50, Loss: 0.9857299847676017\n",
      "Epoch 19/50, Loss: 0.9774245343854665\n",
      "Epoch 20/50, Loss: 0.9697611142912179\n",
      "Epoch 21/50, Loss: 0.9646281523777701\n",
      "Epoch 22/50, Loss: 0.9577163709399036\n",
      "Epoch 23/50, Loss: 0.9509349515675889\n",
      "Epoch 24/50, Loss: 0.946033415587052\n",
      "Epoch 25/50, Loss: 0.9402269868899489\n",
      "Epoch 26/50, Loss: 0.9350691890472647\n",
      "Epoch 27/50, Loss: 0.9282058812773136\n",
      "Epoch 28/50, Loss: 0.9241252771728788\n",
      "Epoch 29/50, Loss: 0.917477637605594\n",
      "Epoch 30/50, Loss: 0.9124051259301812\n",
      "Epoch 31/50, Loss: 0.906593972307337\n",
      "Epoch 32/50, Loss: 0.9018806504166644\n",
      "Epoch 33/50, Loss: 0.8974441090203307\n",
      "Epoch 34/50, Loss: 0.8891230792645604\n",
      "Epoch 35/50, Loss: 0.8876772364387122\n",
      "Epoch 36/50, Loss: 0.88243863908836\n",
      "Epoch 37/50, Loss: 0.8781316495307571\n",
      "Epoch 38/50, Loss: 0.8746853957090841\n",
      "Epoch 39/50, Loss: 0.8692008258436646\n",
      "Epoch 40/50, Loss: 0.8653923692300801\n",
      "Epoch 41/50, Loss: 0.859338817389115\n",
      "Epoch 42/50, Loss: 0.8560891372468465\n",
      "Epoch 43/50, Loss: 0.852563446897375\n",
      "Epoch 44/50, Loss: 0.8474094116169474\n",
      "Epoch 45/50, Loss: 0.844128713735839\n",
      "Epoch 46/50, Loss: 0.8397215319716412\n",
      "Epoch 47/50, Loss: 0.8344526636935866\n",
      "Epoch 48/50, Loss: 0.8325199772939658\n",
      "Epoch 49/50, Loss: 0.8298040041533272\n",
      "Epoch 50/50, Loss: 0.8267388182222996\n",
      "Test Accuracy : 65.00\n"
     ]
    }
   ],
   "source": [
    "train_cosine_loss(teacher=modified_nn_deep, student=modified_nn_light, train_loaders=train_loaders, epochs=50, learning_rate=5e-5, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_accuracy_light_ce_and_cosine_loss = test_outputs(modified_nn_light, test_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedDeepNNRegressor(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedDeepNNRegressor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        conv_feature_map = x\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x, conv_feature_map\n",
    "\n",
    "class ModifiedLightNNRegressor(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedLightNNRegressor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        regressor_output = self.regressor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x, regressor_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_mse_loss(teacher, student, train_loader, epochs, learning_rate, feature_map_weight, ce_loss_weight, device):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval() \n",
    "    student.train() \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, teacher_feature_map = teacher(inputs)\n",
    "\n",
    "            student_logits, regressor_feature_map = student(inputs)\n",
    "\n",
    "            hidden_rep_loss = mse_loss(regressor_feature_map, teacher_feature_map)\n",
    "\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            loss = feature_map_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "modified_nn_light_reg = ModifiedLightNNRegressor(num_classes=10).to(device)\n",
    "\n",
    "\n",
    "modified_nn_deep_reg = ModifiedDeepNNRegressor(num_classes=10).to(device)\n",
    "modified_nn_deep_reg.load_state_dict(nn_deep.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 33.94429340996706\n",
      "Epoch 2/50, Loss: 24.149619846392774\n",
      "Epoch 3/50, Loss: 22.244878217692264\n",
      "Epoch 4/50, Loss: 20.668229783587442\n",
      "Epoch 5/50, Loss: 19.198318949745744\n",
      "Epoch 6/50, Loss: 17.67490135495315\n",
      "Epoch 7/50, Loss: 16.07704192842059\n",
      "Epoch 8/50, Loss: 14.544416320293456\n",
      "Epoch 9/50, Loss: 13.29257458250236\n",
      "Epoch 10/50, Loss: 12.269069025278702\n",
      "Epoch 11/50, Loss: 11.3274664305665\n",
      "Epoch 12/50, Loss: 10.373412415194695\n",
      "Epoch 13/50, Loss: 9.378615784218244\n",
      "Epoch 14/50, Loss: 8.437383891981277\n",
      "Epoch 15/50, Loss: 7.693902702282761\n",
      "Epoch 16/50, Loss: 7.166577001361896\n",
      "Epoch 17/50, Loss: 6.756850480423559\n",
      "Epoch 18/50, Loss: 6.416731303915038\n",
      "Epoch 19/50, Loss: 6.129864102434319\n",
      "Epoch 20/50, Loss: 5.885206888398856\n",
      "Epoch 21/50, Loss: 5.669684583268812\n",
      "Epoch 22/50, Loss: 5.487340044182584\n",
      "Epoch 23/50, Loss: 5.317224620858116\n",
      "Epoch 24/50, Loss: 5.171969450343296\n",
      "Epoch 25/50, Loss: 5.040686625653826\n",
      "Epoch 26/50, Loss: 4.923521397973571\n",
      "Epoch 27/50, Loss: 4.813330021050885\n",
      "Epoch 28/50, Loss: 4.712565134248465\n",
      "Epoch 29/50, Loss: 4.621134253109203\n",
      "Epoch 30/50, Loss: 4.535385646478599\n",
      "Epoch 31/50, Loss: 4.455821390956869\n",
      "Epoch 32/50, Loss: 4.3835692308138094\n",
      "Epoch 33/50, Loss: 4.311843866582417\n",
      "Epoch 34/50, Loss: 4.245861724819369\n",
      "Epoch 35/50, Loss: 4.1841305338818096\n",
      "Epoch 36/50, Loss: 4.127188151449803\n",
      "Epoch 37/50, Loss: 4.072184752930156\n",
      "Epoch 38/50, Loss: 4.020814366352832\n",
      "Epoch 39/50, Loss: 3.972218866543392\n",
      "Epoch 40/50, Loss: 3.9252780489909376\n",
      "Epoch 41/50, Loss: 3.881427004514143\n",
      "Epoch 42/50, Loss: 3.8411839965664214\n",
      "Epoch 43/50, Loss: 3.7996138794647765\n",
      "Epoch 44/50, Loss: 3.7635858821137176\n",
      "Epoch 45/50, Loss: 3.7277193130434627\n",
      "Epoch 46/50, Loss: 3.694580130564892\n",
      "Epoch 47/50, Loss: 3.661012333677248\n",
      "Epoch 48/50, Loss: 3.6318763582907674\n",
      "Epoch 49/50, Loss: 3.6027212429534443\n",
      "Epoch 50/50, Loss: 3.569121078457064\n",
      "Test Accuracy : 65.98\n"
     ]
    }
   ],
   "source": [
    "train_mse_loss(teacher=modified_nn_deep_reg, student=modified_nn_light_reg, train_loader=train_loaders, epochs=50, learning_rate=5e-5, feature_map_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_accuracy_light_ce_and_mse_loss = test_outputs(modified_nn_light_reg, test_loaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher accuracy: 71.77%\n",
      "Student accuracy without teacher: 66.32%\n",
      "Student accuracy with CE + CosineLoss: 65.00%\n",
      "Student accuracy with CE + RegressorMSE: 65.98%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "print(f\"Student accuracy with CE + CosineLoss: {test_accuracy_light_ce_and_cosine_loss:.2f}%\")\n",
    "print(f\"Student accuracy with CE + RegressorMSE: {test_accuracy_light_ce_and_mse_loss:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(modified_nn_light.state_dict(), \"ModefiedNNLight.pth\")\n",
    "torch.save(modified_nn_light_reg.state_dict(),\"ModifiedNNLightReg.pth\")\n",
    "print(\"Final model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image': 'Cars.png', 'predicted_class': 'bird', 'probabilities': [[0.0029290253296494484, 1.4356356814460014e-07, 0.977946937084198, 0.0004215117951389402, 0.01677001267671585, 0.0001279014250030741, 4.4039975932719244e-07, 0.0017982993740588427, 1.0911135994717824e-08, 5.6159269661293365e-06]]}, {'image': 'CyberTruck.jpg', 'predicted_class': 'bird', 'probabilities': [[0.005296729505062103, 0.07268933206796646, 0.6597440242767334, 9.25747663131915e-05, 0.0001061474031303078, 2.6200650609098375e-06, 0.00024029589258134365, 0.00453138817101717, 5.154713562660618e-07, 0.25729644298553467]]}, {'image': 'Deer.jpg', 'predicted_class': 'deer', 'probabilities': [[1.4864350639243185e-08, 1.0849383613731334e-08, 0.006579791195690632, 2.697348827496171e-05, 0.9917028546333313, 0.0015323807019740343, 1.2202338695033177e-08, 0.0001578085357323289, 4.145479803614044e-13, 2.0534912437142339e-07]]}, {'image': 'Dogimage.jpg', 'predicted_class': 'dog', 'probabilities': [[5.954097631599709e-11, 1.8187930545324194e-13, 0.02956211194396019, 1.613957829249557e-05, 0.0012847459875047207, 0.9688090085983276, 3.456735697682234e-08, 0.00032806795206852257, 3.165477049319604e-13, 9.221078067778166e-11]]}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])  \n",
    "])\n",
    "\n",
    "def load_model(model_path : str):\n",
    "    model = DeepNN()\n",
    "    model.load_state_dict(torch.load(model_path,map_location=device,weights_only=False))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_image(image_path, model_path, device=device):\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    \n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "  \n",
    "    predicted_class_idx = torch.argmax(probabilities, dim=1).item()\n",
    "    predicted_class = class_labels[predicted_class_idx]\n",
    "\n",
    "    return predicted_class, probabilities.cpu().numpy()\n",
    "\n",
    "result = []\n",
    "model_path = \"./NNDeep.pth\"  \n",
    "folder_path = \"./EvalDataset\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith((\".png\",\".jpg\",\".jpeg\")):\n",
    "        image_path = os.path.join(folder_path,filename)\n",
    "        predicted_label, probabilities = predict_image(image_path, model_path)\n",
    "        result.append({\n",
    "            \"image\" : filename,\n",
    "            \"predicted_class\":predicted_label,\n",
    "            \"probabilities\" : probabilities.tolist()\n",
    "        })\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted to ONNX: ImagePredictor.onnx\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "dummy_input = torch.randn(1,3,32,32).to(device)\n",
    "onnx_path = \"ImagePredictor.onnx\"\n",
    "model = load_model(model_path=\"./NNDeep.pth\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\" : {0 : \"batch_size\"},\n",
    "        \"output\" : {0 : \"batch_size\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model converted to ONNX: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized ONNX Model: ImagePredictorQuantizedFinalized.onnx\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic , QuantType\n",
    "\n",
    "quantized_onnx_path = \"ImagePredictorQuantizedFinalized.onnx\"\n",
    "\n",
    "onnx_path = \"ImagePredictor.onnx\"\n",
    "\n",
    "quantized_model = quantize_dynamic(\n",
    "    onnx_path,\n",
    "    quantized_onnx_path,\n",
    "    weight_type=QuantType.QUInt8\n",
    ")\n",
    "print(f\"Quantized ONNX Model: {quantized_onnx_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
